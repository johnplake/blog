---
title: "Continual learning in token + capability space (Bluesky thread)"
author: "Cameron (@cameron.stream)"
date: "2026-02-14"
date-added: "2026-02-14"
categories: [AI, agents, continual-learning, memory]
status: to-read
url: "https://bsky.app/profile/cameron.stream/post/3meryue7hds2s"
---

Short Bluesky thread pushing back on “continual learning = weight updates” and arguing that practical continual learning for agents can happen in **token/context space** (memories, skills, prompts, capabilities) because it’s more portable, inspectable, and transferable across model generations.

Includes links to Letta posts:
- [Continual Learning in Token Space | Letta](https://www.letta.com/blog/continual-learning)
- [Skill Learning | Letta](https://www.letta.com/blog/skill-learning)

[Read the thread →](https://bsky.app/profile/cameron.stream/post/3meryue7hds2s)
